
---
title: "Bootstraping the Minimum and Maximum Annual Soil Respiration Differences"
output: 
  html_document:
    fig_caption: no
    number_sections: no
    toc: no
    toc_float: false
    collapsed: no.
---

```{r set-options, echo=FALSE}
options(width = 105)
knitr::opts_chunk$set(dev='png', dpi=300, cache=TRUE)
pdf.options(useDingbats = TRUE)
```
#Estimating the average difference between the minimum and maximum Soil Respiration levels from 1999 t0 2015 in Eastern China

### Edit this to refelect what we are actually doing
A great tool at our disposal here is bootstaping. We have a small number of samples, and to begin with there is an element of estimation in this statsic because it would be nearly impossible and extremely expensive to measure the respiration Levels in soil across all of Eastern China over the course of many years, what we do have is a somewhat sparce data set. 

The question we are askinf isnt if there was a chang at all, but how confident are we that one has or has not occured given the information we have and the information we lack. Throught this project the bigest challenge was dealing with very spread out limited data, however, we have cleaned up our table and we can now run a bootstrap simulation to quantify the confidence interval of the change of the difference between min and max values we (will call the difference now mm_difference and the change of differences total_change from here on out). 

The process of bootstraping is fairly simmple, we will be sampling our cleaned dataset, with replacement, to calculate the total_change between the mm_difference for 1995 and 2015. we will then do this many times to create a normal distribution. this will give us a confidence interval of that change. 

We will do this process multile times and thus create a confedience interval of those as well for an added layer of certainty.
```{r}
library("sf")
library("ggplot2")
library("readr")
library("tidyverse")
library("tibble")
```


```{r}
#import cleaned dataset:
RS_full <- read_csv("china_clean.csv")

#lets just grab the two columns we are interested in:
RS <- RS_full[, c('Study_midyear', 'Rs_annual')]
head(RS)
```

```{r}
#make a function that can compute the mean difference of a dataframe column:
rs_mean <- function (data, i){
  highs_and_lows<- data[i, ] %>% group_by(Study_midyear) %>% summarize(High = max(Rs_annual), Min = min(Rs_annual))
  differences <- (highs_and_lows$High - highs_and_lows$Min)
  return(mean(differences))}
```


```{r}
# import the bootstap package
library(boot)

one_bootstrap <- function(){
  result <- boot(data = RS, statistic = rs_mean, R = 1000)
  return (result)}
```

Great, now we have some infestructure to run bootstrap simulations. 
First off let's investigate one bootstrap iteration and its associated confidence interval:
# visualizing the confidence interval of this one bootstraped simmulation:
```{r}
#get one set bootstrap statistics
boot_results <- one_bootstrap()$t

# find the mean and CI 
boot_mean <- mean(boot_results)
#we are looking at the middle 95%
boot_ci <- quantile(boot_results, c(0.025, 0.975))

# for plotting the data, we can all of the sub iterations into a DataFrame
plot_data <- data.frame(mean_statistic = boot_results)

# Plot using ggplot2
ggplot(plot_data, aes(x = mean_statistic)) +
  geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
  #Plotting the CI
  geom_vline(xintercept = boot_ci[1], color = "red", linetype = "dashed") +
  geom_vline(xintercept = boot_ci[2], color = "red", linetype = "dashed") +
  #plotting the mean
  geom_vline(xintercept = boot_mean, color = "darkgreen", linetype = "dashed") +
  labs(x = "Mean Difference", y = "Frequency") +
  ggtitle("Simulated Mean Difference")
```
lets just make sure we get two different sets of results if we run our simulation agian:
```{r}
#get one set bootstrap statistics
boot_results <- one_bootstrap()$t

# find the mean and CI 
boot_mean <- mean(boot_results)
#we are looking at the middle 95%
boot_ci <- quantile(boot_results, c(0.025, 0.975))

# for plotting the data, we can all of the sub iterations into a DataFrame
plot_data <- data.frame(mean_statistic = boot_results)

# Plot using ggplot2
ggplot(plot_data, aes(x = mean_statistic)) +
  geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
  #Plotting the CI
  geom_vline(xintercept = boot_ci[1], color = "red", linetype = "dashed") +
  geom_vline(xintercept = boot_ci[2], color = "red", linetype = "dashed") +
  #plotting the mean
  geom_vline(xintercept = boot_mean, color = "darkgreen", linetype = "dashed") +
  labs(x = "Mean Difference", y = "Frequency") +
  ggtitle("Simulated Mean Difference")
```
Now we can run this simulation a set number of times to determine the distribution of bootstrapped means and confidence intervals (because you can see that they also vary by simulation)
```{r}

#how many bootstraps to run
n <- 1:100

# Creating an empty dataframe to store each new value of the BS
ci_and_stat <- tibble(
  n = integer(),
  low = double(),
  high = double(), 
  mean_bs = double()
)

# Running the simulation
for (num in n) {
  # Run one bootstrap
  boot_stat <- one_bootstrap()$t
  
  # Get the CIs
  boot_ci <- quantile(boot_stat, c(0.025, 0.975))
  low_ci <- boot_ci[1]
  high_ci <- boot_ci[2]
  
  # Add it to the dataframe
  ci_and_stat <- bind_rows(ci_and_stat, tibble(
    n = num,
    low = low_ci,
    high = high_ci,
    mean_bs = mean(boot_stat)
  ))
}

ci_and_stat

```
Awesome, now we can plot these to see the distribution of confidence intervals and get a pretty good gauge of our simulated statistic:

```{r}
test <- RS %>% group_by(Study_midyear) %>% summarize(High = max(Rs_annual))
test                                        
```

```{r}

#specify our x and y values
x <- ci_and_stat$n
y <- ci_and_stat$mean_bs

#get true mean
highs_and_lows<- RS %>% group_by(Study_midyear) %>% summarize(High = max(Rs_annual), Min = min(Rs_annual))
rs_mean_difference <- mean((highs_and_lows$High - highs_and_lows$Min))

ggplot(ci_and_stat, aes(x, y)) + geom_point() +  
geom_errorbar(aes(ymin = low, ymax = high)) + 
  labs(x="Bootstrap Iteration", y="Annual Respiration", main="Distribution of Confidence Intervals in Relation to Observed Statisitc") + 
   geom_hline(yintercept=rs_mean_difference, color = "Red", linetype="dashed")
  
```
We can see here that our observed mean difference is statistically signigicant. Which means that the value we observed with the current sample doesnt nessicerily reflect that of the true population. 

We will cover the potetal reasons this may be in the next section. 
